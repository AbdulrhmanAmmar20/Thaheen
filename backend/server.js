// backend/server.js
import express from "express";
import cors from "cors";
import fs from "fs/promises";
import path from "path";
import { fileURLToPath } from "url";
import OpenAI from "openai";
import "dotenv/config";

//
// Ø¥Ø¹Ø¯Ø§Ø¯ __dirname ÙÙŠ ES Modules
//
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

//
// Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
//
const PORT = process.env.PORT || 3000;
const TOP_K = 3;            // Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø§Ù„Ø£ÙˆØ§Ø¦Ù„
const brand = "#FD7B06";    // (ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…ØŒ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© ÙÙ‚Ø·)

const openai = new OpenAI();
const app = express();
app.use(express.json());
app.use(cors());

//
// ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª (faq_vectors.json) Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù‚Ù„Ø§Ø¹
//
let faqVectors = [];
async function loadFAQ() {
  try {
    const data = await fs.readFile(
      path.join(__dirname, "data", "faq_vectors.json"),
      "utf8"
    );
    faqVectors = JSON.parse(data);
    console.log("âœ”ï¸Ž FAQ vectors loaded:", faqVectors.length);
  } catch (err) {
    console.error("âŒ Failed to load faq_vectors.json:", err.message);
    process.exit(1);
  }
}
await loadFAQ();

//
// Ø¯Ø§Ù„Ø© Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ ÙƒÙˆØ²Ø§ÙŠÙ† Ø¨ÙŠÙ† Ù…ØªØ¬Ù‡ÙŠÙ†
//
function cosine(a, b) {
  const dot = a.reduce((sum, v, i) => sum + v * b[i], 0);
  const magA = Math.sqrt(a.reduce((sum, v) => sum + v * v, 0));
  const magB = Math.sqrt(b.reduce((sum, v) => sum + v * v, 0));
  return dot / (magA * magB);
}

//
// Ù…Ø³Ø§Ø± Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©
//
app.post("/chat", async (req, res) => {
  try {
    const q = (req.body.q || "").trim();
    if (!q) return res.status(400).json({ error: "empty_question" });

    // 1) ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„
    const embResp = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: q,
    });
    const emb = embResp.data?.[0]?.embedding;
    if (!emb) throw new Error("embedding_failed");

    // 2) Ø±ØªØ¨ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    const candidates = faqVectors
      .filter((f) => Array.isArray(f.vector))
      .map((f) => ({
        ...f,
        score: cosine(f.vector, emb),
      }))
      .sort((a, b) => b.score - a.score);

    // 3) Ø§Ø®ØªØ± Ø£ÙØ¶Ù„ TOP_K Ø¯ÙˆÙ† ÙÙ„ØªØ±Ø© Ø¨Ø§Ù„Ø¹ØªØ¨Ø©
    const top = candidates.slice(0, TOP_K);

    // Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ù…Ø±Ø´Ø­
    if (!top.length) {
      return res.json({
        answer: "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.",
      });
    }

    // 4) Ø¬Ù‡Ù‘Ø² Ø³ÙŠØ§Ù‚ Q/A
    const context = top
      .map((t) => `Q: ${t.question}\nA: ${t.answer}`)
      .join("\n---\n");

    // 5) Ø§Ø·Ù„Ø¨ Ù…Ù† GPTâ€‘4o Ø§Ù„Ø±Ø¯ Ø¨Ø¯Ù‚Ø©
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      temperature: 0,
      messages: [
        {
          role: "system",
          content:
            "Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© (A) Ø§Ù„Ø£Ù‚Ø±Ø¨ Ø¯ÙˆÙ† Ø£ÙŠ Ø¥Ø¶Ø§ÙØ©:\n" + context,
        },
        { role: "user", content: q },
      ],
    });

    return res.json({
      answer: completion.choices[0].message.content.trim(),
    });
  } catch (err) {
    console.error("Backend error:", err);
    return res
      .status(500)
      .json({ error: err.message || "server_error" });
  }
});

//
// ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…
//
app.listen(PORT, () =>
  console.log(`ðŸš€ FAQâ€‘Bot ready on http://localhost:${PORT}`)
);
